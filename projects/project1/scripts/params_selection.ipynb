{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from process_data import *\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from run import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_num_col_index = 22 # Index of PRI_jet_num feature\n",
    "jet_values = [0, 1, 2, 3] # Values taken by PRI_jet_num\n",
    "\n",
    "# Array of indices of raw per jet value\n",
    "subsets_indices_array = indices_split_dataset_jet_num(tX, jet_num_col_index, jet_values)\n",
    "\n",
    "# Remove useless columns from each subset\n",
    "tX_cleaned, all_useless_indices = clean_useless_columns_jet(tX, subsets_indices_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Choose the subset you want to train : (ex: Set 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the subset we want to train on. \n",
    "jet_number = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_c = tX_cleaned[jet_number]\n",
    "y_c = y[subsets_indices_array[jet_number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in a train and test set (80% train , 20% test)\n",
    "x_train, x_test, y_train, y_test = split_data(tX_c, y_c, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"Cross validation function on processed dataset using ridge regression\"\"\"\n",
    "    # Create indices and split data. \n",
    "    indices_train = k_indices[~(np.arange(k_indices.shape[0]) == k)].reshape(-1)\n",
    "    indices_test = k_indices[k]\n",
    "    \n",
    "    x_tr = x[indices_train]\n",
    "    x_te = x[indices_test]\n",
    "    y_tr = y[indices_train]\n",
    "    y_te = y[indices_test]\n",
    "    \n",
    "    # form data with polynomial degree\n",
    "    tx_tr = full_process_data(x_tr, degree, DATA_TRAIN_PATH, all_useless_indices[jet_number], False)\n",
    "    tx_te = full_process_data(x_te, degree, DATA_TRAIN_PATH, all_useless_indices[jet_number], False)\n",
    "    \n",
    "    # ridge regression\n",
    "    w, _ = ridge_regression(y_tr, tx_tr, lambda_)\n",
    "\n",
    "    loss_test = np.sqrt(2 * MSE_loss(y_te, tx_te, w))\n",
    "    \n",
    "    return loss_test, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_lambda_and_degree(y, x, deg_inf, deg_sup, k_fold):\n",
    "    \"\"\" Find the best lambda and degree using cross validation and ridge regression\"\"\"\n",
    "    loss = float('inf')\n",
    "    w_ = 0\n",
    "    \n",
    "    lambdas = np.logspace(-10, -1, 10)\n",
    "    \n",
    "    k_ind = build_k_indices(y, k_fold, 1)\n",
    "    \n",
    "    optimal_degree = 0\n",
    "    optimal_lambda = 0\n",
    "    \n",
    "    for degree in range(deg_inf, (deg_sup+1)):\n",
    "        print(degree)\n",
    "        for l in lambdas:\n",
    "            for k in range(k_fold):\n",
    "                loss_test, w = cross_validation(y, x, k_ind, k, l, degree)\n",
    "                if(loss > loss_test):\n",
    "                    loss = loss_test\n",
    "                    optimal_degree = degree\n",
    "                    optimal_lambda = l\n",
    "                    w_ = w\n",
    "    return loss, w_ , optimal_degree, optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Compute the loss and w as well as pick the best degree and lambda\n",
    "loss, w_ , optimal_degree, optimal_lambda = find_best_lambda_and_degree(y_train, x_train, 1, 10, 4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_degree = 9\n",
      "optimal_lambda = 1e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal_degree = {d}\".format(d=optimal_degree))\n",
    "print(\"optimal_lambda = {d}\".format(d=optimal_lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_lambda(y, x, degree, lambda_, k_fold):\n",
    "    \"\"\"Find a better lambda using linspace from the previouly computed lambda and degree.\"\"\"\n",
    "    \n",
    "    loss = float('inf')\n",
    "    w_ = 0\n",
    "    \n",
    "    lambdas = np.linspace(lambda_/2, 3/2*lambda_, 11)\n",
    "    k_ind = build_k_indices(y, k_fold, 1)\n",
    "\n",
    "    optimal_lambda = 0\n",
    "    \n",
    "    for l in lambdas:\n",
    "        for k in range(k_fold):\n",
    "            loss_test, w = cross_validation(y, x, k_ind, k, l, degree)\n",
    "            if(loss > loss_test):\n",
    "                loss = loss_test\n",
    "                optimal_lambda = l\n",
    "                w_ = w\n",
    "    return loss, w_, optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal w and loss for a more precise best lambda.\n",
    "loss, optimal_w , optimal_lambda2 = find_best_lambda(y_train, x_train, optimal_degree, optimal_lambda, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_lambda =6e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal_lambda ={d}\".format(d=optimal_lambda2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the test set data \n",
    "x_test_clean = full_process_data(x_test, optimal_degree, DATA_TRAIN_PATH, all_useless_indices[jet_number], False)\n",
    "# Make a prediction with the optimal w \n",
    "y_pred_test = predict_labels(optimal_w, x_test_clean)\n",
    "\n",
    "# Compute the accuracy between the prediction and actual y.\n",
    "accuracy = compute_accuracy(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy performed on the train set.\n",
    "x_train_clean = full_process_data(x_train, optimal_degree, DATA_TRAIN_PATH, all_useless_indices[jet_number], False)\n",
    "train_accuracy = compute_accuracy(y_train, predict_labels(optimal_w, x_train_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.8050164420658972, Train accuracy = 0.8057548158297735\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy = {a1}, Train accuracy = {a2}\".format(a1=accuracy, a2=train_accuracy ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
